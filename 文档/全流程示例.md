## 任务简介

从老师发布的文件获取原始数据，解压后通过python程序将大文件分割成940个小文件，然后将文件内容上传到hdfs。然后利用MapReduce代码对文件分别进行处理。

代码的具体逻辑是在Map阶段生成单词和文档ID的键值对并传输给Combine模块，Combine阶段对Map的键值对进行基础的归并和排序，Reduce阶段对单词在每个文件中出现的次数进行相加并写入HBase中。

当用户在HBase中输入搜索内容后，HBase会自动列出该单词和所有存储了该单词的文件。


主要步骤：

- 将大文件切分为多个小文件（可用 `scripts/wordcut.py`），上传至 HDFS 的 `/input/sentences/files/`。
- 在 `java_src/InvertedMapReduce` 中构建 Java MapReduce 程序并提交到集群，Reducer 会直接写入 HBase 表 `InvertedIndexTable`（列族 `info`）。

下面详细说明 Java 程序中每个阶段的实现细节与注意点（Mapper / Combiner / Reducer / Driver）。

## 一、数据准备与上传（简要）

1. 使用仓库提供的 `scripts/wordcut.py` 将 `data/sentences/sentences.txt` 切分为若干 `file*.txt`（每 10000 行为一个文件），输出到 `data/sentences/files/`。
2. 使用上传脚本将这些小文件上传到 HDFS（默认目录 `/input/sentences/files/`）：

```bash
python3 scripts/upload_hdfs.py --overwrite
```

（或用于测试的 `python3 scripts/upload_hdfs_small.py`，只上传前 20 个文件）

## 二、Java MapReduce：各阶段详细说明

下面依据仓库源码 `java_src/InvertedMapReduce/src/main/java/com/test/` 中的实现，逐步说明 Mapper、Combiner、Reducer 与 Driver 的职责与实现细节。

1) Mapper（`InvertedMapper`）

- 输入类型：`LongWritable`（行偏移）和 `Text`（该行文本）。
- 预期每行文本格式：第一列可能为句子编号或元信息，后续字段为空格分隔的单词集合。
- 实现要点：
  - 使用 `context.getInputSplit()` 取得 `FileSplit`，从中获取当前处理的文件名（例如 `file12.txt`）。
  - 将每个单词输出为中间键值对：`key = word:filename`，`value = "1"`。
  - 之所以把文件名包含在 key 中，是为了让 Combiner 可以在 map 端合并同一文件内同一单词的计数，减少 shuffle 流量。

2) Combiner（`InvertedCombiner`）

- Combiner 接收的中间 key 格式为 `word:filename`，values 为多个字符串 "1"（或数字字符串）。
- 实现要点：
  - 对 values 求和，得到该单词在该文件中的出现总数 `count`。
  - 将输出 key 改写为纯单词 `word`，value 输出为 `filename:count`。
  - 示例：输入 `<"hadoop:file12.txt", ["1","1","1"]>` → 输出 `<"hadoop", "file12.txt:3">`。

3) Reducer（`InvertedReducer`，继承自 `TableReducer`）

- Reducer 接收 `key = word`，`values` 为若干 `filename:count` 字符串（来自 Combiner 或直接来自 Mapper）。
- 实现要点：
  - 将所有 `filename:count` 以分号 `;` 拼接成一个字符串（例如 `file12.txt:3;file27.txt:1;`）。
  - 使用单词 `word` 作为 HBase 的 row key，构造 `Put`，并将拼接结果写入表的 `info:index` 列（即 `put 'InvertedIndexTable', 'hadoop', 'info:index', 'file12.txt:3;file27.txt:1;'`）。
  - Reducer 作为 `TableReducer`，其 `context.write(null, put)` 会把数据写到通过 `TableMapReduceUtil` 初始化的 HBase 表中。

4) Driver（`Driver`）

- 职责：组装、配置并提交 Hadoop Job。实现要点：
  - 创建 `Configuration` 并显式设置关键参数（示例中设置了 `fs.defaultFS`、`yarn.resourcemanager.hostname`、`hbase.zookeeper.quorum`），确保在不同部署环境中可控地连接 HDFS/YARN/HBase。
  - 设置 `Mapper`、`Combiner`、`Reducer` 类，并设置 map 输出 key/value 类型为 `Text`。
  - 使用 `TableMapReduceUtil.initTableReducerJob("InvertedIndexTable", InvertedReducer.class, job)` 将 Reducer 配置为写入 HBase 的 TableReducer（表名可按实际改）。
  - 读取命令行输入路径 `args[0]` 作为 Job 的输入目录（通常为 HDFS 的 `/input/sentences/files`）。
  - 通过 `job.waitForCompletion(true)` 等待任务完成并返回退出码。

## 三、运行示例（构建与提交）

1. 在仓库目录下构建 Java 程序：

```bash
cd java_src/InvertedMapReduce
./gradlew build
```

2. 找到生成的 jar（通常在 `build/libs/` 下），用 Hadoop 提交作业：

```bash
# 假设 jar 名称为 InvertedMapReduce-1.0-SNAPSHOT.jar
hadoop jar build/libs/InvertedMapReduce-1.0-SNAPSHOT.jar /input/sentences/files
```

说明：Driver 内部会用 `args[0]` 读取输入路径，上例将 `/input/sentences/files` 作为输入目录。Driver 已在 `Configuration` 中示例性地设置了 HDFS 名称节点和 HBase/ZK 的地址；在实际集群运行时，请根据你集群的实际配置调整这些设置或改为通过外部配置注入。

---
