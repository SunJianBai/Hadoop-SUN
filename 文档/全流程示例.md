## 任务简介

从老师发布的文件获取原始数据，解压后通过python程序将大文件分割成940个小文件，然后将文件内容上传到hdfs。然后利用MapReduce代码对文件分别进行处理。

代码的具体逻辑是在Map阶段生成单词和文档ID的键值对并传输给Combine模块，Combine阶段对Map的键值对进行基础的归并和排序，Reduce阶段对单词在每个文件中出现的次数进行相加并写入HBase中。

当用户在HBase中输入搜索内容后，HBase会自动列出该单词和所有存储了该单词的文件。


## 一、准备原始数据（文本语料）

sentence.txt，一共有9397023行，每行有一个行号（0-9397022）和一个英文长句，相邻单词用空格分离。数据中仅包含数字与英文字母，无特殊符号。

  运行wordcut.py将同目录下的sentence.txt按照每一万行句子进行划分，并将划分好的940个文件命名为files0~files939，并存入files文件夹中。

```python
import os
import math
# 指定输入文件和输出目录
input_file_path = r"sentences.txt"  # 输入的txt文件路径
output_directory = r'files'  # 指定的输出目录路径
# 打开原始txt文件,一共有9397023条句子
with open(input_file_path, 'r', encoding='utf-8') as input_file:
    lines = input_file.readlines()
# 计算总行数和文件数
total_lines = len(lines)
num_files = (total_lines + 9999) // 10000
# 分割文件
for i in range(num_files):
    start = i * 10000
    end = min((i + 1) * 10000, total_lines)
    output_filename = os.path.join(output_directory, f'file{i}.txt')

    # 写入分割后的内容到新文件
    with open(output_filename, 'w', encoding='utf-8') as output_file:
        output_file.writelines(lines[start:end])
```


使用java程序里面的UpLoad类将本地处理好的数据集上传到集群hdfs的“input/data/”目录下。


此时，数据已经存在于  **HDFS** （分布式存储），准备给 MapReduce 使用。

---

## 二、编写 MapReduce 程序（倒排索引）

### 目标：

生成类似下面的倒排索引（word → 出现在哪些文档里）：

```
big       doc3
data      doc3
fast      doc1
hadoop    doc1, doc2, doc3
is        doc1, doc2
needs     doc3
scalable  doc2
```

### Map 阶段：

    生成单词和文档ID的键值对

1. **输入数据格式** ：

* `LongWritable key`：文件中当前处理行的偏移量，作为行号。
* `Text value`：代表文件中的一行数据，假设每行数据包含一个句子编号及其对应的句子文本。

2. **输出键值对** ：

* **键 (`Text`)** ：格式为 `word:filename`，表示某个单词出现在某个文件中。
* **值 (`Text`)** ：固定为 `"1"`，表示每次遇到该单词在该文件中出现一次。



### Combine阶段

 对Map的键值对进行基础的归并和排序




### Reduce 阶段：

* 把相同的 word 聚合，合并所有文档 ID，得到：
  ```
  hadoop → [doc1, doc2, doc3]
  ```

---

## 三、运行 MapReduce 任务

假设已经写好 `InvertedIndex.java` 并打包成 `InvertedIndex.jar`，运行：

```bash
hadoop jar InvertedIndex.jar InvertedIndex /input /output
```

任务会在集群上执行，结果存储到 HDFS 的 `/output` 路径。

---

## 四、查看结果

```bash
hdfs dfs -cat /output/part-r-00000
```

可能输出：

```
big       doc3
data      doc3
fast      doc1
hadoop    doc1,doc2,doc3
is        doc1,doc2
needs     doc3
scalable  doc2
```

这就是  **倒排索引** 。

---

## 五、把结果导入 HBase

启动 HBase Shell：

```bash
hbase shell
```

创建表：

```hbase
create 'inverted_index', 'docs'
```

写入数据（假设结果文件在本地处理过后，写入 HBase）：

```hbase
put 'inverted_index', 'hadoop', 'docs:list', 'doc1,doc2,doc3'
put 'inverted_index', 'fast', 'docs:list', 'doc1'
put 'inverted_index', 'scalable', 'docs:list', 'doc2'
```

---

## 六、查询（模拟搜索）

用户查询 "hadoop" 时，在 HBase 里查：

```hbase
get 'inverted_index', 'hadoop'
```

输出：

```
COLUMN                   CELL
 docs:list               doc1,doc2,doc3
```

这表示 "hadoop" 出现在 **doc1, doc2, doc3** 三个文档中。

---

## 七、全流程回顾

1. **HDFS** → 存原始大数据文件。
2. **MapReduce** → 批量计算倒排索引。
3. **HBase** → 存储计算结果，支持快速查询。
4. **ZooKeeper** → 协调 HBase 的分布式环境

---
