## 任务简介

从老师发布的文件获取原始数据，解压后通过python程序将大文件分割成940个小文件，然后将文件内容上传到hdfs。然后利用MapReduce代码对文件分别进行处理。代码的具体逻辑是在Map阶段生成单词和文档ID的键值对并传输给Combine模块，Combine阶段对Map的键值对进行基础的归并和排序，Reduce阶段对单词在每个文件中出现的次数进行相加并写入HBase中。

当用户在HBase中输入搜索内容后，HBase会自动列出该单词和所有存储了该单词的文件。


## 一、准备原始数据（文本语料）

假设我们有一个文件 `sentences.txt`，内容是：

```
hadoop is fast
hadoop is scalable
big data needs hadoop
```

把它放到  **本地** ，然后上传到 HDFS。

```bash
hdfs dfs -mkdir /input
hdfs dfs -put sentences.txt /input/
```

此时，数据已经存在于  **HDFS** （分布式存储），准备给 MapReduce 使用。

---

## 二、编写 MapReduce 程序（倒排索引）

### 目标：

生成类似下面的倒排索引（word → 出现在哪些文档里）：

```
big       doc3
data      doc3
fast      doc1
hadoop    doc1, doc2, doc3
is        doc1, doc2
needs     doc3
scalable  doc2
```

### Map 阶段：

* 输入：一行文本，例如 `hadoop is fast`，它属于 doc1。
* 输出：`(word, docID)`，例如：
  ```
  (hadoop, doc1)
  (is, doc1)
  (fast, doc1)
  ```

### Reduce 阶段：

* 把相同的 word 聚合，合并所有文档 ID，得到：
  ```
  hadoop → [doc1, doc2, doc3]
  ```

---

## 三、运行 MapReduce 任务

假设已经写好 `InvertedIndex.java` 并打包成 `InvertedIndex.jar`，运行：

```bash
hadoop jar InvertedIndex.jar InvertedIndex /input /output
```

任务会在集群上执行，结果存储到 HDFS 的 `/output` 路径。

---

## 四、查看结果

```bash
hdfs dfs -cat /output/part-r-00000
```

可能输出：

```
big       doc3
data      doc3
fast      doc1
hadoop    doc1,doc2,doc3
is        doc1,doc2
needs     doc3
scalable  doc2
```

这就是  **倒排索引** 。

---

## 五、把结果导入 HBase

启动 HBase Shell：

```bash
hbase shell
```

创建表：

```hbase
create 'inverted_index', 'docs'
```

写入数据（假设结果文件在本地处理过后，写入 HBase）：

```hbase
put 'inverted_index', 'hadoop', 'docs:list', 'doc1,doc2,doc3'
put 'inverted_index', 'fast', 'docs:list', 'doc1'
put 'inverted_index', 'scalable', 'docs:list', 'doc2'
```

---

## 六、查询（模拟搜索）

用户查询 "hadoop" 时，在 HBase 里查：

```hbase
get 'inverted_index', 'hadoop'
```

输出：

```
COLUMN                   CELL
 docs:list               doc1,doc2,doc3
```

这表示 "hadoop" 出现在 **doc1, doc2, doc3** 三个文档中。

---

## 七、全流程回顾

1. **HDFS** → 存原始大数据文件。
2. **MapReduce** → 批量计算倒排索引。
3. **HBase** → 存储计算结果，支持快速查询。
4. **ZooKeeper** → 协调 HBase 的分布式环境

---
