## 任务简介

从老师发布的文件获取原始数据，解压后通过python程序将大文件分割成940个小文件，然后将文件内容上传到hdfs。然后利用MapReduce代码对文件分别进行处理。

代码的具体逻辑是在Map阶段生成单词和文档ID的键值对并传输给Combine模块，Combine阶段对Map的键值对进行基础的归并和排序，Reduce阶段对单词在每个文件中出现的次数进行相加并写入HBase中。

当用户在HBase中输入搜索内容后，HBase会自动列出该单词和所有存储了该单词的文件。


### 数据库设计

**任务内容：**

* 设计hbase数据库，可以编造测试数据存入。
* 编写代码 ，用于在HBase中输入需要查询的词，呈现查询 结果
* 可以通过可视化的方式，模仿搜索引擎的web ui

**交付物：**

- 数据处理后存入hbase的格式
- 查询数据库的源码

---

### **测试工程师（完全分布式）**

配置完全分布环境

在完全分布的环境下跑通全流程任务

**交付物：**

* 运行 MapReduce 程序，观察日志、截图

---

### 测试工程师（伪分布)

在单机伪分布的环境下跑通全流程任务

**交付物：**

* 运行 MapReduce 程序，观察日志、截图

---

### 代码编写

**任务内容：**

- 编写 MapReduce 程序（倒排索引）
- 将处理过的数据存入hbase

**交付物：**

- 代码源码
- 编译打包项目为 jar

* 运行 MapReduce 程序，观察日志、截图
* 在报告里写 **技术选型、实现步骤**

---

### 文档编写

**任务内容：**

* 整理项目开发全流程，编写文档
* 撰写报告的 **结果分析与总结**

---
