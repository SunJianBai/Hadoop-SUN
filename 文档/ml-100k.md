## 数据集

### 数据集准备

我采用的数据集是 `MovieLens 100K`。一个记录了电影评价的数据集。

下面的命令可以下载并解压数据集文件到本地。

```bash
wget http://files.grouplens.org/datasets/movielens/ml-100k.zip -O ml-100k.zip
unzip ml-100k.zip -d ml-100k
```

- 把数据解压到本地目录，方便后续逐文件上传或一次性上传目录。

然后可以运行 `jps`来确认当前HDFS是否在运行。

````bash
# jps 列出当前 JVM 进程（查看 NameNode/DataNode/ResourceManager/NodeManager 等）
jps
````

- jps 能快速看到 NameNode、DataNode 等进程是否在运行。若没有看到 NameNode/DataNode，需要先启动 Hadoop（start-dfs.sh / start-yarn.sh）。

### 上传到HDFS

可以运行 `scripts/upload_ml100k_to_hdfs.sh` 这个shell脚本，这个脚本实现了把刚才解压的数据集导入到HDFS中。

下面几行是对hdfs文件系统的基本操作，和对linux文件系统的操作有点相似。

```bash
hdfs dfs -mkdir /input
hdfs dfs -put localfile.txt /input
hdfs dfs -ls /input
hdfs dfs -cat /input/localfile.txt
hdfs dfs -rm /input/localfile.txt
```

下面介绍的是这个脚本中实现的基本功能。

1. 在 HDFS 上创建目标目录（按用户隔离，推荐放到 /user/$USER 下）

````bash
# 在 HDFS 上创建放置数据的目录（-p：如果上级目录不存在就一并创建）
hdfs dfs -mkdir -p /user/$USER/input/ml-100k
# 查看是否创建成功
hdfs dfs -ls -d /user/$USER/input/ml-100k
````

- /user/$USER 是 Hadoop 推荐的用户目录，便于管理权限与后续运行 MR/YARN 作业时默认路径。
- -p 可以一次创建多级目录，避免中间报错。

2. 上传数据集中的关键文件（例如 u.data）

````bash
#!/bin/bash
hdfs dfs -put ml-100k/u.data /user/$USER/input/ml-100k/u.data
# 或者改名存放
hdfs dfs -put ml-100k/u.data /user/$USER/input/ml-100k-u.data
# 验证文件内容（只看前几行）
hdfs dfs -cat /user/$USER/input/ml-100k/u.data | head -n 20
````

说明：

- 如果只需某个文件，单独上传可以节省时间。
- hdfs dfs -cat 可以在终端查看文件内容并用管道 head 查看前若干行，确认上传正确。

3. 检查上传结果与空间占用

````bash
#!/bin/bash
# 列出目录树（-R 递归）
hdfs dfs -ls -R /user/$USER/input/ml-100k
# 查看 HDFS 占用（-h 人类可读）
hdfs dfs -du -h /user/$USER/input/ml-100k
````

说明：

- -ls -R 可以确认所有文件是否都到位；-du -h 看文件占用大小、用于判断是否完整上传。

4. （单机伪分布）把副本数设为 1（可选，但推荐）

````bash
#!/bin/bash
# 把上传目录及其文件副本数统一设置为1，避免单机上生成多份浪费空间
hdfs dfs -setrep -R -w 1 /user/$USER/input/ml-100k
# 检查设置是否生效（查看副本数）
hdfs dfs -ls -R /user/$USER/input/ml-100k | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}'
````

说明：

- 单机伪分布下默认副本可能仍然是1，但显式设置能避免在某些配置下出现多副本导致磁盘占用增大。
- -R 递归，-w 等待操作完成。

5. 如果遇到权限问题：修改 HDFS 上该目录的所有者或权限

````bash
#!/bin/bash
# 把 HDFS 上的目录所属用户改为当前用户（需要有权限的情况下）
hdfs dfs -chown -R $USER:$USER /user/$USER/input/ml-100k
# 或修改权限（例如所有人可读）
hdfs dfs -chmod -R 755 /user/$USER/input/ml-100k
````



## 运行流程与说明

### 准备（前提）

```bash
jps    # 应该能看到 NameNode、DataNode、ResourceManager、NodeManager 等进程
```

- 已把 ml-100k 数据上传到 HDFS（推荐路径：`/user/$USER/input/ml-100k`）。如果没上传，可运行：

```bash
chmod +x scripts/ml-100/upload_ml100k_to_hdfs.sh

    该脚本会把本地`data/ml-100k/ml-100k/u.data`、`u.item`、`u.user` 上传到 HDFS，并做基本校验。

- 运行/入口脚本（一键示例）：`scripts/run_streaming_examples.sh`
- 与 ml-100k 相关的 mapper/reducer 脚本都放到：`scripts/ml-100/`，包括：
  - `mapper_count_movie.py` / `reducer_count_movie.py` （统计每部电影被评分次数）
  - `reducer_join_title.py` （把 movie_id 替换成电影标题，需要把本地 `u.item` 通过 `-files` 发送）
  - `upload_ml100k_to_hdfs.sh`（上传数据到 HDFS 的便捷脚本）

这些脚本都已经带有详细注释，适合逐行阅读学习。

### 一键运行示例（集群/YARN 模式）
在仓库根目录运行：

```bash
chmod +x scripts/run_streaming_examples.sh
./scripts/run_streaming_examples.sh
```

脚本会按顺序执行三个 streaming 作业并在终端显示示例输出：

1) 统计每部电影被评分次数 → 输出到 HDFS `/user/$USER/output/movie_counts`；脚本打印 top20。
2) 计算每部电影平均评分 → 输出到 HDFS `/user/$USER/output/movie_avg`；脚本打印按平均评分排序的 top20。
3) 用电影名替换 movie_id（join）→ 输入取自上一步输出，输出到 `/user/$USER/output/movie_avg_named`，脚本会把 `u.item` 文件分发到 reducer 来做内存 join，然后打印若干行结果。

- 第一步（计数）

  - 为什么：演示 MapReduce 的典型计数模式（WordCount 的变体），理解 Mapper 输出、Shuffle、Reducer 聚合流程。
- 第二步（平均评分）

  - Mapper (`mapper_avg.py`)：从 `u.data` 输出 `movie_id\trating`。
  - Reducer (`reducer_avg.py`)：对相同 movie_id 求 sum/count 并输出 `movie_id\tavg\tcount`。
  - 为什么：演示如何在 reducer 做聚合计算（sum、count、avg），并学会在 reducer 中处理数值与异常行。
- 第三步（join 映射 movie_id -> title）

  - Reducer (`reducer_join_title.py`)：在启动时把本地 `u.item` 文件读入内存（movie_id->title 字典），然后把 stdin 的 movie_id 映射为 title 输出。
  - 为什么：展示如何在 streaming 作业中把小表（u.item）作为 side data 发到各个 reducer 做内存 join（常用于维表 join）。

### 如何查看结果与验证

- 查看 HDFS 输出目录的文件：

```bash
hdfs dfs -ls /user/$USER/output/movie_avg_named
hdfs dfs -cat /user/$USER/output/movie_avg_named/part-* | head -n 50
```

- 使用 `sort` 与 `head` 可以本地对结果做快速筛选（脚本里已演示）。
- 在 YARN UI（http://localhost:8088）和 NameNode UI（http://localhost:9870）可以查看作业与 HDFS 状态与作业日志链接。

### 常见错误与排查（你可能会遇到的）

- 错误：AM 或容器启动失败，prelaunch.err 中出现“找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster”。

  - 原因：YARN 启动容器时的类路径没有包含 MapReduce 运行时 jar（`yarn.application.classpath` 未配置或失效）。
  - 解决：在 `$HADOOP_HOME/etc/hadoop/yarn-site.xml` 中设置 `yarn.application.classpath`（包含 `$HADOOP_HOME/share/hadoop/mapreduce/*` 等路径），然后重启 YARN：
    ```bash
    $HADOOP_HOME/sbin/stop-yarn.sh
    $HADOOP_HOME/sbin/start-yarn.sh
    jps   # 验证 ResourceManager 和 NodeManager 重启
    ```
  - 另外，如果 `yarn logs` 无法获取日志（Log Aggregation = DISABLED），需要在 NodeManager 本地目录（通常 `/tmp/hadoop-yarn-*`）查找容器的 `prelaunch.err` 或 stderr。
- 错误：Hadoop Streaming 报错找不到脚本或权限问题

  - 解决：确保在 `-file` 中传入的脚本路径正确，且脚本在本地具有可执行权限（`chmod +x scripts/ml-100/*.py`）。
- 错误：输出目录已存在

  - 解决：在运行前删除旧输出目录，脚本已经包含 `hdfs dfs -rm -r -skipTrash <out>` 来自动删除旧目录。

### local 模式回退（当 YARN 有问题时立刻继续学习）

如果 YARN 环境暂时不可用，你可以把作业强制为 local 模式（map/reduce 在本地 JVM 中运行，便于调试）：

```bash
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar \
	-Dmapreduce.framework.name=local \
	-input /user/$USER/input/ml-100k/u.data \
	-output /user/$USER/output_local/movie_counts \
	-mapper scripts/ml-100/mapper_count_movie.py \
	-reducer scripts/ml-100/reducer_count_movie.py \
	-file scripts/ml-100/mapper_count_movie.py -file scripts/ml-100/reducer_count_movie.py
```

local 模式不会通过 YARN 提交容器，适合在学习阶段快速跑通 mapper/reducer 逻辑。

### 小结

- 本文档现在既包含了原始的 ml-100k 数据说明与上传示例，也包含了完整的运行流程、脚本位置、每一步“具体做了什么”、结果查看方法与常见故障排查步骤。
- 建议按顺序：上传数据 → 运行 `./scripts/run_streaming_examples.sh`（若 YARN 有问题则用 local 回退）→ 在 UI 与日志中阅读作业详情与 stderr，逐步理解 MapReduce 的执行与资源调度。
